services:
  backend:
    build: ./backend
    env_file: .env
    ports: ["8000:8000"]
    depends_on: [db, rabbitmq]
    volumes:
      - ./data:/app/data  # Share data volume

  worker:
    build: ./worker
    env_file: .env
    command: celery -A worker.main worker -l info
    depends_on: [backend, rabbitmq]
    volumes:
      - ./data:/app/data  # Share data volume

  streamlit:
    build: ./frontend_streamlit
    environment:
      - DATA_DIR=/data
    volumes:
      - ./frontend_streamlit:/app
      - ./data:/data
    ports: ["8501:8501"]
    env_file: .env
    depends_on: [backend]
    restart: unless-stopped

  # AI Training service (optional - for containerized training)
  ai-training:
    build: ./ai_training
    environment:
      - DATA_DIR=/data
    volumes:
      - ./data:/data
      - ./ai_training:/workspace
      - ./models:/models
    working_dir: /workspace
    profiles: ["training"]  # Only start when explicitly requested
    command: ["python", "scripts/data_pipeline.py"]

  db:
    image: postgres:15
    environment:
      POSTGRES_USER: util_ai
      POSTGRES_PASSWORD: util_ai
      POSTGRES_DB: util_ai
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports: ["5432:5432"]

  rabbitmq:
    image: rabbitmq:3-management
    ports: ["15672:15672", "5672:5672"]
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq

  minio:
    image: minio/minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports: ["9000:9000", "9001:9001"]
    volumes:
      - minio_data:/data

volumes:
  postgres_data:
  rabbitmq_data:
  minio_data:
